{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonard\\miniconda3\\envs\\openmmlab\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from dataclasses import dataclass, field\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from datetime import datetime\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import requests\n",
    "from pysolotools.consumers import Solo\n",
    "from pysolotools.converters.solo2coco import SOLO2COCOConverter\n",
    "from pysolotools.core.models import KeypointAnnotationDefinition, RGBCameraCapture\n",
    "from typing import Dict, List, Tuple\n",
    "from pysolotools.core.models import Frame, BoundingBox2DLabel, BoundingBox2DAnnotation\n",
    "\n",
    "import torch\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "import base_new as base\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../../Projects/mmdetection/checkpoints/mask_rcnn_swin-t-p4-w7_fpn_fp16_ms-crop-3x_coco_20210908_165006-90a4008c.pth\n"
     ]
    }
   ],
   "source": [
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "resnet = resnet18(weights=weights)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "resnet = resnet.eval().cuda()\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "config_file = '../../Projects/mmdetection/configs/swin/mask_rcnn_swin-t-p4-w7_fpn_fp16_ms-crop-3x_coco.py'\n",
    "checkpoint_file = '../../Projects/mmdetection/checkpoints/mask_rcnn_swin-t-p4-w7_fpn_fp16_ms-crop-3x_coco_20210908_165006-90a4008c.pth'\n",
    "obj_det = init_detector(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = 'C:/Users/Leonard/AppData/LocalLow/DefaultCompany/Perception2/solo_16'\n",
    "solo = Solo(data_path=folder_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame has multi-capture instances from multi-camera  \n",
    "Each capture has multiple annotations, one of which is a 2DBoundingBox annotation  \n",
    "For the 2DBoundingBox annotation, there is a list of 2DBoundingBoxLabel represents the number of objects  \n",
    "We convert the 2DBoundingBoxLabel to Custom2DBoundingBoxLabel to hold the box's light ray  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocationLabel(metadata={}, instanceId=1, labelId=1, position=array([3.529252  , 1.11557269, 1.5095558 ]))\n",
      "LocationLabel(metadata={}, instanceId=2, labelId=1, position=array([1.47503769, 1.11557269, 1.8960123 ]))\n",
      "step0.camera_0.png\n",
      "LocationLabel(metadata={}, instanceId=1, labelId=1, position=array([3.5292511 , 1.11557269, 1.5095576 ]))\n",
      "LocationLabel(metadata={}, instanceId=2, labelId=1, position=array([1.4750366 , 1.11557269, 1.89601445]))\n",
      "step0.camera.png\n",
      "\n",
      "0.02257075310730816\n"
     ]
    }
   ],
   "source": [
    "reload(base)\n",
    "\n",
    "pred_errs = []\n",
    "for frame_idx, frame in enumerate(solo.frames()):\n",
    "    # print(f'\\r{frame_idx}/{len(solo.frames())}', end='')\n",
    "    deep_frame = base.DeepFrame.from_frame(frame, f'{solo.data_path}/sequence.{frame_idx}', obj_det, resnet, preprocess)\n",
    "    for instanceId, item in deep_frame.loc_gt.items():\n",
    "        # print(instanceId, item['pred_err'])\n",
    "        pred_errs.append(item['pred_err'])\n",
    "    break\n",
    "\n",
    "print()\n",
    "print(np.mean(pred_errs), np.var(pred_errs), np.min(pred_errs), np.max(pred_errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03129284307616376"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028579350000000003\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([3.51531737, 1.10592773, 1.50455604])\n",
    "gt = np.array([3.529252, 1.11557269, 1.5095558])\n",
    "\n",
    "print(np.sqrt((pred - gt)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09d746b8f7d49e4d7c870418bd04bb5a79717e9e3cc6f92d77e11e9d41b7621"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
