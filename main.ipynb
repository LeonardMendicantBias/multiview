{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from typing import List\n",
    "from base import Scene\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "config_file = '../../Projects/mmdetection/configs/swin/mask_rcnn_swin-t-p4-w7_fpn_fp16_ms-crop-3x_coco.py'\n",
    "checkpoint_file = '../../Projects/mmdetection/checkpoints/mask_rcnn_swin-t-p4-w7_fpn_fp16_ms-crop-3x_coco_20210908_165006-90a4008c.pth'\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "# model_ = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "resnet = resnet18(weights=weights)\n",
    "resnet = resnet.eval().cuda()\n",
    "preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = 'C:/Users/Leonard/AppData/LocalLow/DefaultCompany/Perception2/solo_3'\n",
    "# folder_dir = 'C:/Users/Leonard/AppData/LocalLow/DefaultCompany/Perception2/solo_6'\n",
    "# folder_dir = './data/solo/'\n",
    "\n",
    "errs = []\n",
    "preds, gts = [], []\n",
    "for i in range(20):\n",
    "    f_dir = f'{folder_dir}/sequence.{i}'\n",
    "    with open(f'{f_dir}/step0.frame_data.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    captures = data['captures']\n",
    "\n",
    "    scene = Scene.from_captures(f_dir, captures, model, resnet, preprocess)\n",
    "    # scene.show_gt_bboxes()\n",
    "    # scene.show_pred_bboxes()\n",
    "    # scene._object_pairing()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_coor = [\n",
    "    np.array([0, 0, 15]),\n",
    "    np.array([3, 0, 15]),\n",
    "    np.array([0, 3, 15]),\n",
    "    np.array([3, 3, 15]),\n",
    "]\n",
    "\n",
    "focal = 20.78461\n",
    "resolution = np.array([3840, 2160])\n",
    "sensor = np.array([30, 30])\n",
    "intrinsic = np.array([\n",
    "    [focal*resolution[0]/sensor[0], 0, 0],\n",
    "    [0, -focal*resolution[0]/sensor[0], 0],\n",
    "    [resolution[0]/2, resolution[1]/2, 1],\n",
    "])\n",
    "ndc_coor = [np.matmul(coor, intrinsic) for coor in camera_coor]\n",
    "\n",
    "pixel_coor = [np.floor((coor/coor[-1])[:-1]) for coor in ndc_coor]\n",
    "for coor_a, coor_b in zip(pixel_coor, ndc_coor):\n",
    "    print(coor_a, \"|\", coor_b/coor_b[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_to_world(pixel_coor):\n",
    "    homo_coor = [np.insert(coor, 2, 1) for coor in pixel_coor]\n",
    "\n",
    "    coor = [np.matmul(coor, np.linalg.inv(intrinsic)) for coor in homo_coor]\n",
    "\n",
    "    return coor\n",
    "\n",
    "coors = camera_to_world(pixel_coor)\n",
    "for coor in coors:\n",
    "    print(coor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm(quaternion1, quaternion0):\n",
    "    w0, x0, y0, z0 = quaternion0\n",
    "    w1, x1, y1, z1 = quaternion1\n",
    "    \n",
    "    return np.array([\n",
    "        -x1*x0 - y1*y0 - z1*z0 + w1*w0,\n",
    "         x1*w0 - y1*z0 + z1*y0 + w1*x0,\n",
    "         x1*z0 + y1*w0 - z1*x0 + w1*y0,\n",
    "        -x1*y0 + y1*x0 + z1*w0 + w1*z0\n",
    "    ])\n",
    "\n",
    "q = np.array([0, 1, 0, 0])\n",
    "abc = [\n",
    "    np.array([0, 2, 1.5, 0]),\n",
    "]\n",
    "d = np.array([2, 2, 5])\n",
    "\n",
    "_inv = np.array([1, -1, -1, -1])\n",
    "print(\n",
    "    qm(qm(q, abc[0]), q*_inv), qm(qm(q, abc[0]), q*_inv)[1:] - d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09d746b8f7d49e4d7c870418bd04bb5a79717e9e3cc6f92d77e11e9d41b7621"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
